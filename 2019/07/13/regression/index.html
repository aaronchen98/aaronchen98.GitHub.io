<!DOCTYPE html>
<html lang>
  <head><meta name="generator" content="Hexo 3.9.0">
    
<meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0, minimum-scale=0.5, maximum-scale=2.0, user-scalable=yes">


<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">



  <meta name="description" content="Regression">




  <meta name="keywords" content="机器学习,">







  <link rel="alternate" href="/atom.xml" title="浩瀚宇宙·AaronChen">




  <link rel="shortcut icon" type="image/x-icon" href="/img/1.jpg?v=1.1">



<link rel="canonical" href="https://hhyz.me/2019/07/13/regression/">


<meta name="description" content="basic null hypothesis (原假设)：假设 X 和 Y 并没有关系 alternative hypothesis (备选假设)：假设 X 和 Y 是有关系的  统计量 t 值： $$t=\frac{\overline{x}-\mu_{0}}{s / \sqrt{n}}$$ 回归评价指标Residual Standard Error $$\operatorname{RSE}=\sq">
<meta name="keywords" content="机器学习">
<meta property="og:type" content="article">
<meta property="og:title" content="Regression">
<meta property="og:url" content="https://hhyz.me/2019/07/13/regression/index.html">
<meta property="og:site_name" content="浩瀚宇宙·AaronChen">
<meta property="og:description" content="basic null hypothesis (原假设)：假设 X 和 Y 并没有关系 alternative hypothesis (备选假设)：假设 X 和 Y 是有关系的  统计量 t 值： $$t=\frac{\overline{x}-\mu_{0}}{s / \sqrt{n}}$$ 回归评价指标Residual Standard Error $$\operatorname{RSE}=\sq">
<meta property="og:locale" content="zh">
<meta property="og:image" content="https://hhyz.me/img/2019-07-13-regression-1.png">
<meta property="og:updated_time" content="2019-07-14T14:17:03.348Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Regression">
<meta name="twitter:description" content="basic null hypothesis (原假设)：假设 X 和 Y 并没有关系 alternative hypothesis (备选假设)：假设 X 和 Y 是有关系的  统计量 t 值： $$t=\frac{\overline{x}-\mu_{0}}{s / \sqrt{n}}$$ 回归评价指标Residual Standard Error $$\operatorname{RSE}=\sq">
<meta name="twitter:image" content="https://hhyz.me/img/2019-07-13-regression-1.png">


<link rel="stylesheet" type="text/css" href="/css/style.css?v=1.1">
<link href="https://fonts.googleapis.com/css?family=Open+Sans" rel="stylesheet">





<script type="text/javascript">
  var themeConfig = {
    fancybox: {
      enable: false
    },
  };
</script>




  
  <script type="text/javascript">
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?3cbfa43ed54bb06d8da192dc667bed80";
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(hm, s);
    })();
  </script>


  <script type="text/javascript">
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
        (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
        m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
        })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

        ga('create', 'UA-139198240-1', 'auto');
        ga('send', 'pageview');
  </script>





  


    <title> Regression - 浩瀚宇宙·AaronChen </title>


    <script>
(function(u, c) {
  var d = document, t = 'script', o = d.createElement(t),
      s = d.getElementsByTagName(t)[0];
  o.src = u;
  if (c) { o.addEventListener('load', function(e) { c(e); }); }
  s.parentNode.insertBefore(o, s);
})('//cdn.bootcss.com/pangu/3.3.0/pangu.min.js', function() {
  pangu.spacingPage();
});
</script>



<script type="text/javascript">
window.onload=
function(){
    var oDiv = document.getElementById("toc-test"),
    H = 0,
    Y = oDiv
    while (Y) {H += Y.offsetTop; Y = Y.offsetParent}
    window.onscroll = function()
    {
        var s = document.body.scrollTop || document.documentElement.scrollTop
        if(s>H) {
            oDiv.style = "position:fixed;top:0;"
        } else {
            oDiv.style = ""
        }
    }
}
</script>






  </head>

  <body>
    <div id="page">
      <header id="masthead"><div class="site-header-inner">
    <h1 class="site-title">
        <a href="/." class="logo">浩瀚宇宙·AaronChen</a>
    </h1>

    <nav id="nav-top">
        
            <ul id="menu-top" class="nav-top-items">
                
                    <li class="menu-item">
                        <a href="https://www.hhyz.me">
                            
                            
                                Gallery
                            
                        </a>
                    </li>
                
                    <li class="menu-item">
                        <a href="/about">
                            
                            
                                About
                            
                        </a>
                    </li>
                
            </ul>
        
  </nav>
</div>

      </header>
      <div id="content">
        
    <div id="primary">
        
  <article class="post">
    <header class="post-header">
      <h1 class="post-title">
        
          Regression
        
      </h1>

      <time class="post-time">
          Jul 13 2019
      </time>
    </header>



    
            <div class="post-content">
            <h1 id="basic"><a href="#basic" class="headerlink" title="basic"></a>basic</h1><ul>
<li>null hypothesis (原假设)：假设 X 和 Y 并没有关系</li>
<li>alternative hypothesis (备选假设)：假设 X 和 Y 是有关系的</li>
</ul>
<p>统计量 t 值：</p>
<p>$$<br>t=\frac{\overline{x}-\mu_{0}}{s / \sqrt{n}}<br>$$</p>
<h2 id="回归评价指标"><a href="#回归评价指标" class="headerlink" title="回归评价指标"></a>回归评价指标</h2><p><strong>Residual Standard Error</strong></p>
<p>$$<br>\operatorname{RSE}=\sqrt{\frac{1}{n-2} \operatorname{RSS}}=\sqrt{\frac{1}{n-2} \sum_{i=1}^{n}\left(y_{i}-\hat{y}_{i}\right)^{2}}<br>$$</p>
<p><strong>residual sum-of-squares</strong></p>
<p>$$<br>R S S=\sum_{i=1}^{n}\left(y_{i}-\hat{y}_{i}\right)^{2}<br>$$</p>
<p><strong>R-squared</strong></p>
<p>$$<br>R^{2}=\frac{\mathrm{TSS}-\mathrm{RSS}}{\mathrm{TSS}}=1-\frac{\mathrm{RSS}}{\mathrm{TSS}} =1-\frac{\sum(y-\hat{y})^{2}}{\sum(y-\overline{y})^{2}}<br>$$</p>
<p><strong>total sum of squares</strong></p>
<p>$$<br>\mathrm{TSS}=\sum_{i=1}^{n}\left(y_{i}-\overline{y}\right)^{2}<br>$$</p>
<p>在简单线性回归中：</p>
<p>$$<br>R^{2}=r^{2}<br>$$</p>
<p>其中 \( r \) 是\( X \) 和\( Y \)的相关系数</p>
<p>$$<br>r=\frac{\sum_{i=1}^{n}\left(x_{i}-\overline{x}\right)\left(y_{i}-\overline{y}\right)}{\sqrt{\sum_{i=1}^{n}\left(x_{i}-\overline{x}\right)^{2}} \sqrt{\sum_{i=1}^{n}\left(y_{i}-\overline{y}\right)^{2}}}<br>$$</p>
<h1 id="linear-regression"><a href="#linear-regression" class="headerlink" title="linear regression"></a>linear regression</h1><h2 id="single-predictor"><a href="#single-predictor" class="headerlink" title="single predictor"></a>single predictor</h2><p>假设模型为：</p>
<p>$$<br>Y=\beta_{0}+\beta_{1} X+\epsilon<br>$$</p>
<ul>
<li>\( \beta_{0} \) 被称为 intercept</li>
<li>\( \beta_{1} \) 被称为 slope</li>
</ul>
<p>给出估计值 \( \hat{\beta}_{0} \) 和 \( \hat{\beta}_{1} \)，我们预测：</p>
<p>$$<br>\hat{y}=\hat{\beta}_{0}+\hat{\beta}_{1} x<br>$$</p>
<ul>
<li>hat 符号代表是估计值</li>
</ul>
<p>使 residual 为：</p>
<p>$$<br>e_{i}=y_{i}-\hat{y}_{i}<br>$$</p>
<p>residual sum of squares (RSS) 为：</p>
<p>$$<br>\mathrm{RSS}=e_{1}^{2}+e_{2}^{2}+\cdots+e_{n}^{2}<br>$$</p>
<p>等同于：</p>
<p>$$<br>\mathrm{RSS}=\left(y_{1}-\hat{\beta}_{0}-\hat{\beta}_{1} x_{1}\right)^{2}+\left(y_{2}-\hat{\beta}_{0}-\hat{\beta}_{1} x_{2}\right)^{2}+\ldots+\left(y_{n}-\hat{\beta}_{0}-\hat{\beta}_{1} x_{n}\right)^{2}<br>$$</p>
<p>为了最小化 RSS，我们得到：</p>
<p>$$<br>\hat{\beta}_{1}=\frac{\sum_{i=1}^{n}\left(x_{i}-\overline{x}\right)\left(y_{i}-\overline{y}\right)}{\sum_{i=1}^{n}\left(x_{i}-\overline{x}\right)^{2}}<br>$$</p>
<p>$$<br>\hat{\beta}_{0}=\overline{y}-\hat{\beta}_{1} \overline{x}<br>$$</p>
<p>$$<br>\begin{array}{l}{\text { where } \overline{y} \equiv \frac{1}{n} \sum_{i=1}^{n} y_{i} \text { and } \overline{x} \equiv \frac{1}{n} \sum_{i=1}^{n} x_{i} \text { are the sample }} \ {\text { means. }}\end{array}<br>$$</p>
<h2 id="Multiple-Linear-Regression"><a href="#Multiple-Linear-Regression" class="headerlink" title="Multiple Linear Regression"></a>Multiple Linear Regression</h2><p>模型为：</p>
<p>$$<br>Y=\beta_{0}+\beta_{1} X_{1}+\beta_{2} X_{2}+\cdots+\beta_{p} X_{p}+\epsilon<br>$$</p>
<p>给出估计值 \( \hat{\beta}_{0}, \hat{\beta}_{1}, \ldots \hat{\beta}_{p} \) 我们预测：</p>
<p>$$<br>\hat{y}=\hat{\beta}_{0}+\hat{\beta}_{1} x_{1}+\hat{\beta}_{2} x_{2}+\cdots+\hat{\beta}_{p} x_{p}<br>$$</p>
<p>$$<br>\begin{aligned} \mathrm{RSS} &amp;=\sum_{i=1}^{n}\left(y_{i}-\hat{y}_{i}\right)^{2} \ &amp;=\sum_{i=1}^{n}\left(y_{i}-\hat{\beta}_{0}-\hat{\beta}_{1} x_{i 1}-\hat{\beta}_{2} x_{i 2}-\cdots-\hat{\beta}_{p} x_{i p}\right)^{2} \end{aligned}<br>$$</p>
<p>最小化 RSS 的 \( \hat{\beta}_{0}, \hat{\beta}_{1}, \ldots \hat{\beta}_{p} \) 就是 multiple least squares regression coefficient estimates。</p>
<h1 id="Model-selection"><a href="#Model-selection" class="headerlink" title="Model selection"></a>Model selection</h1><h2 id="Forward-selection"><a href="#Forward-selection" class="headerlink" title="Forward selection"></a>Forward selection</h2><ol>
<li>从一个 null model 开始（一个只有 intercept 没有 predictors 的模型）</li>
</ol>
<h2 id="Backward-selection"><a href="#Backward-selection" class="headerlink" title="Backward selection"></a>Backward selection</h2><ol>
<li>从包含所有变量的模型开始</li>
<li>移除最大 p 值的变量，也就是最小显著性的变量</li>
<li>拟合新的 (p-1) 变量的模型，再次移除最大 p 值的变量</li>
<li>重复直到满足阈值条件</li>
</ol>
<h1 id="Logistic-Regression"><a href="#Logistic-Regression" class="headerlink" title="Logistic Regression"></a>Logistic Regression</h1><p>$$<br>p(X)=\frac{e^{\beta_{0}+\beta_{1} X}}{1+e^{\beta_{0}+\beta_{1} X}}<br>$$</p>
<p>可以看出不论参数如何变化， \( p(X) \)的值始终在 0 和 1 内</p>
<p><img src="/img/2019-07-13-regression-1.png" alt></p>
<p>如果进行一点转变，被称为 log odds 或者 logit transformation of \( p(X) \)，则有：</p>
<p>$$<br>\log \left(\frac{p(X)}{1-p(X)}\right)=\beta_{0}+\beta_{1} X<br>$$</p>
<p>我们使用极大似然来进行参数估计：</p>
<p>$$<br>\ell\left(\beta_{0}, \beta\right)=\prod_{i : y_{i}=1} p\left(x_{i}\right) \prod_{i : y_{i}=0}\left(1-p\left(x_{i}\right)\right)<br>$$</p>
<p>对于多个变量：</p>
<p>$$<br>\log \left(\frac{p(X)}{1-p(X)}\right)=\beta_{0}+\beta_{1} X_{1}+\cdots+\beta_{p} X_{p}<br>$$</p>
<p>$$<br>p(X)=\frac{e^{\beta_{0}+\beta_{1} X_{1}+\cdots+\beta_{p} X_{p}}}{1+e^{\beta_{0}+\beta_{1} X_{1}+\cdots+\beta_{p} X_{p}}}<br>$$</p>
<p>对于多于两个类：</p>
<p>$$<br>\operatorname{Pr}(Y=k | X)=\frac{e^{\beta_{0 k}+\beta_{1 k} X_{1}+\ldots+\beta_{p k} X_{p}}}{\sum_{\ell=1}^{K} e^{\beta_{0 \ell}+\beta_{1 \ell} X_{1}+\ldots+\beta_{p \ell} X_{p}}}<br>$$</p>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_HTMLorMML" async></script>
            </div>
          

    
      <footer class="post-footer">
        <div class="post-tags">
          
            <a href="/tags/机器学习/">机器学习</a>
          
        </div>

        <div class="post-tags">
          
            <a href="/categories/机器学习/">机器学习</a>
          
        </div>

        
        
  <nav class="post-nav">
    
    
      <a class="next" href="/2019/07/12/papers/">
        <span class="next-text nav-default">论文笔记</span>
        <span class="prev-text nav-mobile">Next</span>
        <i class="iconfont icon-right"></i>
      </a>
    
  </nav>

        
  <div class="comments" id="comments">
    
  </div>


      </footer>
    
  </article>

    </div>


      <div class="post-toc-warp">
        
      <!--noindex-->
          <div class="post-toc" id="toc-test">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#basic"><span class="nav-text">basic</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#回归评价指标"><span class="nav-text">回归评价指标</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#linear-regression"><span class="nav-text">linear regression</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#single-predictor"><span class="nav-text">single predictor</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Multiple-Linear-Regression"><span class="nav-text">Multiple Linear Regression</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Model-selection"><span class="nav-text">Model selection</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Forward-selection"><span class="nav-text">Forward selection</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Backward-selection"><span class="nav-text">Backward selection</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Logistic-Regression"><span class="nav-text">Logistic Regression</span></a></li></ol></div>
            

            <div class="back-to-top" id="back-to-top">
              <i class="iconfont icon-up"></i>
            </div>

          </div>
      <!--/noindex-->
      
      </div>


      </div>
      <footer id="colophon"><span class="copyright-year">
    
        &copy;
    
        2017 -
    
    2019
    <span class="footer-author">haoyu.</span>
    <span class="power-by">
        Powered by <a class="hexo-link" href="https://hexo.io/">Hexo</a> and <a class="theme-link" href="https://github.com/henryhuang/hexo-theme-polarbearsimple">Polar Bear Simple</a>
    </span>
</span>

      </footer>


    </div>
    


    




  
    <script type="text/javascript" src="/lib/jquery/jquery-3.1.1.min.js"></script>
  

  

    <script type="text/javascript" src="/js/src/theme.js?v=1.1"></script>
<script type="text/javascript" src="/js/src/bootstrap.js?v=1.1"></script>

  </body>
</html>
