<!DOCTYPE html>
<html lang="en">
<head><meta name="generator" content="Hexo 3.9.0">
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="google-site-verification" content="xBT4GhYoi5qRD5tr338pgPM5OWHHIDR6mNg1a3euekI">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content>
    <meta name="keyword" content>
    <link rel="shortcut icon" href="/img/favicon.ico">

    <title>
        
        TensorFlow 并行计算 - undefined
        
    </title>

    <!-- Custom CSS -->
    <link rel="stylesheet" href="/css/aircloud.css">
    <link rel="stylesheet" href="/css/gitment.css">
    <!--<link rel="stylesheet" href="https://imsun.github.io/gitment/style/default.css">-->
    <link href="//at.alicdn.com/t/font_620856_pl6z7sid89qkt9.css" rel="stylesheet" type="text/css">
    <!-- ga & ba script hoook -->
    <script></script>
</head>

<body>

<div class="site-nav-toggle" id="site-nav-toggle">
    <button>
        <span class="btn-bar"></span>
        <span class="btn-bar"></span>
        <span class="btn-bar"></span>
    </button>
</div>

<div class="index-about">
    <i>  </i>
</div>

<div class="index-container">
    
    <div class="index-left">
        
<div class="nav" id="nav">
    <div class="avatar-name">
        <div class="avatar ">
            <img src="/" />
        </div>
        <div class="name">
            <i>haoyu</i>
        </div>
    </div>
    <div class="contents" id="nav-content">
        <ul>
            <li >
                <a href="/">
                    <i class="iconfont icon-shouye1"></i>
                    <span>HOME</span>
                </a>
            </li>
            <li >
                <a href="/tags">
                    <i class="iconfont icon-biaoqian1"></i>
                    <span>TAGS</span>
                </a>
            </li>
            <li >
                <a href="/archives">
                    <i class="iconfont icon-guidang2"></i>
                    <span>ARCHIVES</span>
                </a>
            </li>
            <li >
                <a href="/about/">
                    <i class="iconfont icon-guanyu2"></i>
                    <span>ABOUT</span>
                </a>
            </li>
            
        </ul>
    </div>
    
        <div id="toc" class="toc-article">
    <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#多-GPU"><span class="toc-text">多 GPU</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#简述"><span class="toc-text">简述</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#限制-GPU-资源"><span class="toc-text">限制 GPU 资源</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#动态申请显存"><span class="toc-text">动态申请显存</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#限制GPU使用率"><span class="toc-text">限制GPU使用率</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#例一"><span class="toc-text">例一</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#例二"><span class="toc-text">例二</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#多线程"><span class="toc-text">多线程</span></a></li></ol>
</div>
    
</div>


<div class="search-field" id="search-field">
    <div class="search-container">
        <div class="search-input">
            <span id="esc-search"> <i class="icon-fanhui iconfont"></i></span>
            <input id="search-input"/>
            <span id="begin-search">search</span>
        </div>
        <div class="search-result-container" id="search-result-container">

        </div>
    </div>
</div>

        <div class="index-about-mobile">
            <i>  </i>
        </div>
    </div>
    
    <div class="index-middle">
        <!-- Main Content -->
        


<div class="post-container">
    <div class="post-title">
        TensorFlow 并行计算
    </div>

    <div class="post-meta">
        <span class="attr">Post：<span>2019-07-03 01:05:20</span></span>
        
        <span class="attr">Tags：/
        
        <a class="tag" href="/tags/#TensorFlow" title="TensorFlow">TensorFlow</a>
        <span>/</span>
        
        
        </span>
        <span class="attr">Visit：<span id="busuanzi_value_page_pv"></span>
</span>
</span>
    </div>
    <div class="post-content ">
        <h2 id="多-GPU"><a href="#多-GPU" class="headerlink" title="多 GPU"></a>多 GPU</h2><h3 id="简述"><a href="#简述" class="headerlink" title="简述"></a>简述</h3><p>如果有两块卡，但是代码里不设置的话，默认把变量都放到 <code>device(&#39;/gpu:0&#39;)</code>，所以只有 gpu 0 在计算。</p>
<p>tensorflow 默认是占满显存的，然后等到程序需要用的时候直接拿来用，这个是 tensorflow 设计的一个机制，对于这一机制大家褒贬不一</p>
<h3 id="限制-GPU-资源"><a href="#限制-GPU-资源" class="headerlink" title="限制 GPU 资源"></a>限制 GPU 资源</h3><h4 id="动态申请显存"><a href="#动态申请显存" class="headerlink" title="动态申请显存"></a>动态申请显存</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">config = tf.ConfigProto()</span><br><span class="line">config.gpu_options.allow_growth = <span class="literal">True</span></span><br><span class="line">session = tf.Session(config=config)</span><br></pre></td></tr></table></figure>

<h4 id="限制GPU使用率"><a href="#限制GPU使用率" class="headerlink" title="限制GPU使用率"></a>限制GPU使用率</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">gpu_options=tf.GPUOptions(per_process_gpu_memory_fraction=<span class="number">0.333</span>)</span><br><span class="line">config=tf.ConfigProto(gpu_options=gpu_options)</span><br><span class="line">session = tf.Session(config=config)</span><br></pre></td></tr></table></figure>

<p>其中0.333是你自己设置的想用百分之多少的显存。</p>
<h3 id="例一"><a href="#例一" class="headerlink" title="例一"></a>例一</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Multi GPU computing</span></span><br><span class="line"><span class="comment"># GPU:0 computes A^n</span></span><br><span class="line"><span class="keyword">with</span> tf.device(<span class="string">'/gpu:0'</span>):</span><br><span class="line">    <span class="comment">#compute A^n and store result in c2</span></span><br><span class="line">    a = tf.constant(A)</span><br><span class="line">    c2.append(matpow(a, n))</span><br><span class="line"></span><br><span class="line"><span class="comment">#GPU:1 computes B^n</span></span><br><span class="line"><span class="keyword">with</span> tf.device(<span class="string">'/gpu:1'</span>):</span><br><span class="line">    <span class="comment">#compute B^n and store result in c2</span></span><br><span class="line">    b = tf.constant(B)</span><br><span class="line">    c2.append(matpow(b, n))</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.device(<span class="string">'/cpu:0'</span>):</span><br><span class="line">  sum = tf.add_n(c2) <span class="comment">#Addition of all elements in c2, i.e. A^n + B^n</span></span><br><span class="line"></span><br><span class="line">t1_2 = datetime.datetime.now()</span><br><span class="line"><span class="keyword">with</span> tf.Session(config=tf.ConfigProto(log_device_placement=log_device_placement)) <span class="keyword">as</span> sess:</span><br><span class="line">    <span class="comment"># Runs the op.</span></span><br><span class="line">    sess.run(sum)</span><br><span class="line">t2_2 = datetime.datetime.now()</span><br></pre></td></tr></table></figure>

<h3 id="例二"><a href="#例二" class="headerlink" title="例二"></a>例二</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Place all ops on CPU by default</span></span><br><span class="line"><span class="keyword">with</span> tf.device(<span class="string">'/cpu:0'</span>):</span><br><span class="line">    tower_grads = []</span><br><span class="line">    reuse_vars = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># tf Graph input</span></span><br><span class="line">    X = tf.placeholder(tf.float32, [<span class="literal">None</span>, num_input])</span><br><span class="line">    Y = tf.placeholder(tf.float32, [<span class="literal">None</span>, num_classes])</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Loop over all GPUs and construct their own computation graph</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(num_gpus):</span><br><span class="line">        <span class="keyword">with</span> tf.device(assign_to_device(<span class="string">'/gpu:&#123;&#125;'</span>.format(i), ps_device=<span class="string">'/cpu:0'</span>)):</span><br><span class="line"></span><br><span class="line">            <span class="comment"># Split data between GPUs</span></span><br><span class="line">            _x = X[i * batch_size: (i+<span class="number">1</span>) * batch_size]</span><br><span class="line">            _y = Y[i * batch_size: (i+<span class="number">1</span>) * batch_size]</span><br><span class="line"></span><br><span class="line">            <span class="comment"># Because Dropout have different behavior at training and prediction time, we</span></span><br><span class="line">            <span class="comment"># need to create 2 distinct computation graphs that share the same weights.</span></span><br><span class="line"></span><br><span class="line">            <span class="comment"># Create a graph for training</span></span><br><span class="line">            logits_train = conv_net(_x, num_classes, dropout,</span><br><span class="line">                                    reuse=reuse_vars, is_training=<span class="literal">True</span>)</span><br><span class="line">            <span class="comment"># Create another graph for testing that reuse the same weights</span></span><br><span class="line">            logits_test = conv_net(_x, num_classes, dropout,</span><br><span class="line">                                   reuse=<span class="literal">True</span>, is_training=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># Define loss and optimizer (with train logits, for dropout to take effect)</span></span><br><span class="line">            loss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(</span><br><span class="line">                logits=logits_train, labels=_y))</span><br><span class="line">            optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)</span><br><span class="line">            grads = optimizer.compute_gradients(loss_op)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># Only first GPU compute accuracy</span></span><br><span class="line">            <span class="keyword">if</span> i == <span class="number">0</span>:</span><br><span class="line">                <span class="comment"># Evaluate model (with test logits, for dropout to be disabled)</span></span><br><span class="line">                correct_pred = tf.equal(tf.argmax(logits_test, <span class="number">1</span>), tf.argmax(_y, <span class="number">1</span>))</span><br><span class="line">                accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))</span><br><span class="line"></span><br><span class="line">            reuse_vars = <span class="literal">True</span></span><br><span class="line">            tower_grads.append(grads)</span><br><span class="line"></span><br><span class="line">    tower_grads = average_gradients(tower_grads)</span><br><span class="line">    train_op = optimizer.apply_gradients(tower_grads)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Initializing the variables</span></span><br><span class="line">    init = tf.global_variables_initializer()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Launch the graph</span></span><br><span class="line">    <span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">        sess.run(init)</span><br><span class="line">        step = <span class="number">1</span></span><br><span class="line">        <span class="comment"># Keep training until reach max iterations</span></span><br><span class="line">        <span class="keyword">for</span> step <span class="keyword">in</span> range(<span class="number">1</span>, num_steps + <span class="number">1</span>):</span><br><span class="line">            <span class="comment"># Get a batch for each GPU</span></span><br><span class="line">            batch_x, batch_y = mnist.train.next_batch(batch_size * num_gpus)</span><br><span class="line">            <span class="comment"># Run optimization op (backprop)</span></span><br><span class="line">            ts = time.time()</span><br><span class="line">            sess.run(train_op, feed_dict=&#123;X: batch_x, Y: batch_y&#125;)</span><br><span class="line">            te = time.time() - ts</span><br><span class="line">            <span class="keyword">if</span> step % display_step == <span class="number">0</span> <span class="keyword">or</span> step == <span class="number">1</span>:</span><br><span class="line">                <span class="comment"># Calculate batch loss and accuracy</span></span><br><span class="line">                loss, acc = sess.run([loss_op, accuracy], feed_dict=&#123;X: batch_x,</span><br><span class="line">                                                                     Y: batch_y&#125;)</span><br><span class="line">                print(<span class="string">"Step "</span> + str(step) + <span class="string">": Minibatch Loss= "</span> + \</span><br><span class="line">                      <span class="string">"&#123;:.4f&#125;"</span>.format(loss) + <span class="string">", Training Accuracy= "</span> + \</span><br><span class="line">                      <span class="string">"&#123;:.3f&#125;"</span>.format(acc) + <span class="string">", %i Examples/sec"</span> % int(len(batch_x)/te))</span><br><span class="line">            step += <span class="number">1</span></span><br><span class="line">        print(<span class="string">"Optimization Finished!"</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Calculate accuracy for 1000 mnist test images</span></span><br><span class="line">        print(<span class="string">"Testing Accuracy:"</span>, \</span><br><span class="line">            np.mean([sess.run(accuracy, feed_dict=&#123;X: mnist.test.images[i:i+batch_size],</span><br><span class="line">            Y: mnist.test.labels[i:i+batch_size]&#125;) <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>, len(mnist.test.images), batch_size)]))</span><br></pre></td></tr></table></figure>

<ol>
<li><a href="https://github.com/aymericdamien/TensorFlow-Examples/blob/master/notebooks/6_MultiGPU/multigpu_basics.ipynb" target="_blank" rel="noopener">multigpu_basics (code)</a>     </li>
<li><a href="https://github.com/aymericdamien/TensorFlow-Examples/blob/master/notebooks/6_MultiGPU/multigpu_cnn.ipynb" target="_blank" rel="noopener">Multi-GPU Training Example (code)</a></li>
<li><a href="https://www.zhihu.com/question/56291568" target="_blank" rel="noopener">tensorflow 发现两块卡的显存都占用，但是实际上只有一块卡在运算</a></li>
</ol>
<h2 id="多线程"><a href="#多线程" class="headerlink" title="多线程"></a>多线程</h2><p>在进行 <code>tf.ConfigProto()</code> 初始化时，我们也可以通过设置 <code>intra_op_parallelism_threads</code> 参数和 <code>inter_op_parallelism_threads</code> 参数，来控制每个操作符op并行计算的线程个数。</p>
<p><strong>二者的区别在于:</strong></p>
<p> <code>intra_op_parallelism_threads</code> 控制运算符op内部的并行   </p>
<p>当运算符op为单一运算符，并且内部可以实现并行时，如矩阵乘法，<code>reduce_sum</code>之类的操作，可以通过设置 <code>intra_op_parallelism_threads</code> 参数来并行, intra 代表内部。   </p>
<p><code>inter_op_parallelism_threads</code> 控制多个运算符op之间的并行计算</p>
<p>当有多个运算符 op，并且他们之间比较独立，运算符和运算符之间没有直接的路径Path相连。Tensorflow 会尝试并行地计算他们，使用由 <code>inter_op_parallelism_threads</code> 参数来控制数量的一个线程池。</p>
<p>以上两个参数如果设置为0代表让系统设置合适的数值</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">config = tf.ConfigProto(device_count=&#123;<span class="string">"CPU"</span>: <span class="number">4</span>&#125;, <span class="comment"># limit to num_cpu_core CPU usage</span></span><br><span class="line">                inter_op_parallelism_threads = <span class="number">1</span>, </span><br><span class="line">                intra_op_parallelism_threads = <span class="number">4</span>,</span><br><span class="line">                log_device_placement=<span class="literal">True</span>)</span><br><span class="line"><span class="keyword">with</span> tf.Session(config = config) <span class="keyword">as</span> sess:</span><br><span class="line">  <span class="comment"># To Do</span></span><br></pre></td></tr></table></figure>

<p>实例比较，线程数为2和4，平均每个batch的运行时间：</p>
<p>当参数为intra_op_parallelism_threads = 2时, 每个step的平均运行时间从610ms降低到380ms。<br>当参数为intra_op_parallelism_threads = 4时, 每个step的平均运行时间从610ms降低到230ms。</p>
<p>总结，在固定CPUcore的资源限制下，通过合理设置线程thread个数可以明显提升tensorflow程序运行速度。</p>

        
        <br />
        <div id="comment-container">
        </div>
        <div id="disqus_thread"></div>

        <div id="lv-container">
        </div>

    </div>
</div>

    </div>
</div>


<footer class="footer">
    <ul class="list-inline text-center">
        
        

        

        

        

        

    </ul>
    
    <p>
        <span id="busuanzi_container_site_pv">
            <span id="busuanzi_value_site_pv"></span>PV
        </span>
        <span id="busuanzi_container_site_uv">
            <span id="busuanzi_value_site_uv"></span>UV
        </span>
        Created By <a href="https://hexo.io/">Hexo</a>  Theme <a href="https://github.com/aircloud/hexo-theme-aircloud">AirCloud</a></p>
</footer>




</body>

<script>
    // We expose some of the variables needed by the front end
    window.hexo_search_path = ""
    window.hexo_root = "/"
    window.isPost = true
</script>
<script src="https://cdn.bootcss.com/jquery/3.3.1/jquery.min.js"></script>
<script src="/js/index.js"></script>
<script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>




</html>
