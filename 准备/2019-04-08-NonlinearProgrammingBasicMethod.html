<!DOCTYPE html>
<html lang>
  <head><meta name="generator" content="Hexo 3.9.0">
    
<meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0, minimum-scale=0.5, maximum-scale=2.0, user-scalable=yes">


<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">



  <meta name="description" content="NONLINEAR PROGRAMMING BASIC METHODS">




  <meta name="keywords" content=",">







  <link rel="alternate" href="/atom.xml" title="浩瀚宇宙·AaronChen">




  <link rel="shortcut icon" type="image/x-icon" href="/img/1.jpg?v=1.1">



<link rel="canonical" href="https://hhyz.me/准备/2019-04-08-NonlinearProgrammingBasicMethod.html">


<meta name="description" content="1. 梯度法次梯度法（subgradient method）是传统梯度下降方法的拓展，用来处理不可微（non-differentiable ）的凸函数。它的优势是比传统方法处理问题范围大，但劣势是算法收敛速度慢。而传统的梯度下降方法只能处理可导函数。   其实无论是梯度法还是次梯度法，本质上我们都在使用一阶泰勒展开式的原理去逼近在某点的原函数。正如泰勒展开式的思想所述，将目标函数在某点附近展开为泰">
<meta name="keywords" content="机器学习">
<meta property="og:type" content="website">
<meta property="og:title" content="NONLINEAR PROGRAMMING BASIC METHODS">
<meta property="og:url" content="https://hhyz.me/准备/2019-04-08-NonlinearProgrammingBasicMethod.html">
<meta property="og:site_name" content="浩瀚宇宙·AaronChen">
<meta property="og:description" content="1. 梯度法次梯度法（subgradient method）是传统梯度下降方法的拓展，用来处理不可微（non-differentiable ）的凸函数。它的优势是比传统方法处理问题范围大，但劣势是算法收敛速度慢。而传统的梯度下降方法只能处理可导函数。   其实无论是梯度法还是次梯度法，本质上我们都在使用一阶泰勒展开式的原理去逼近在某点的原函数。正如泰勒展开式的思想所述，将目标函数在某点附近展开为泰">
<meta property="og:locale" content="zh">
<meta property="og:image" content="https://ws1.sinaimg.cn/large/006tKfTcgy1g1ggxz0sqgj309u05xdg7.jpg">
<meta property="og:updated_time" content="2019-07-02T17:09:45.502Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="NONLINEAR PROGRAMMING BASIC METHODS">
<meta name="twitter:description" content="1. 梯度法次梯度法（subgradient method）是传统梯度下降方法的拓展，用来处理不可微（non-differentiable ）的凸函数。它的优势是比传统方法处理问题范围大，但劣势是算法收敛速度慢。而传统的梯度下降方法只能处理可导函数。   其实无论是梯度法还是次梯度法，本质上我们都在使用一阶泰勒展开式的原理去逼近在某点的原函数。正如泰勒展开式的思想所述，将目标函数在某点附近展开为泰">
<meta name="twitter:image" content="https://ws1.sinaimg.cn/large/006tKfTcgy1g1ggxz0sqgj309u05xdg7.jpg">


<link rel="stylesheet" type="text/css" href="/css/style.css?v=1.1">
<link href="https://fonts.googleapis.com/css?family=Open+Sans" rel="stylesheet">





<script type="text/javascript">
  var themeConfig = {
    fancybox: {
      enable: false
    },
  };
</script>




  
  <script type="text/javascript">
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?3cbfa43ed54bb06d8da192dc667bed80";
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(hm, s);
    })();
  </script>


  <script type="text/javascript">
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
        (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
        m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
        })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

        ga('create', 'UA-139198240-1', 'auto');
        ga('send', 'pageview');
  </script>





  


    <title> NONLINEAR PROGRAMMING BASIC METHODS - 浩瀚宇宙·AaronChen </title>


    <script>
(function(u, c) {
  var d = document, t = 'script', o = d.createElement(t),
      s = d.getElementsByTagName(t)[0];
  o.src = u;
  if (c) { o.addEventListener('load', function(e) { c(e); }); }
  s.parentNode.insertBefore(o, s);
})('//cdn.bootcss.com/pangu/3.3.0/pangu.min.js', function() {
  pangu.spacingPage();
});
</script>



<script type="text/javascript">
window.onload=
function(){
    var oDiv = document.getElementById("toc-test"),
    H = 0,
    Y = oDiv
    while (Y) {H += Y.offsetTop; Y = Y.offsetParent}
    window.onscroll = function()
    {
        var s = document.body.scrollTop || document.documentElement.scrollTop
        if(s>H) {
            oDiv.style = "position:fixed;top:0;"
        } else {
            oDiv.style = ""
        }
    }
}
</script>






  </head>

  <body>
    <div id="page">
      <header id="masthead"><div class="site-header-inner">
    <h1 class="site-title">
        <a href="/." class="logo">浩瀚宇宙·AaronChen</a>
    </h1>

    <nav id="nav-top">
        
            <ul id="menu-top" class="nav-top-items">
                
                    <li class="menu-item">
                        <a href="https://www.hhyz.me">
                            
                            
                                Gallery
                            
                        </a>
                    </li>
                
                    <li class="menu-item">
                        <a href="/about">
                            
                            
                                About
                            
                        </a>
                    </li>
                
            </ul>
        
  </nav>
</div>

      </header>
      <div id="content">
        
    <div id="primary">
        <article class="post">
            <header class="post-header">
                <h1 class="post-title">
                    NONLINEAR PROGRAMMING BASIC METHODS
                </h1>
            </header>
            <div class="post-content">
                <h2 id="1-梯度法"><a href="#1-梯度法" class="headerlink" title="1. 梯度法"></a>1. 梯度法</h2><p>次梯度法（subgradient method）是传统梯度下降方法的拓展，用来处理不可微（non-differentiable ）的凸函数。它的优势是比传统方法处理问题范围大，但劣势是算法收敛速度慢。而传统的梯度下降方法只能处理可导函数。</p>
<p><img src="https://ws1.sinaimg.cn/large/006tKfTcgy1g1ggxz0sqgj309u05xdg7.jpg" alt></p>
<blockquote>
<p>其实无论是梯度法还是次梯度法，本质上我们都在使用一阶泰勒展开式的原理去逼近在某点的原函数。正如泰勒展开式的思想所述，将目标函数在某点附近展开为泰勒(Taylor)多项式来逼近原函数。</p>
</blockquote>
<h3 id="Gradient-Algorithm-with-Exact-Line-Search"><a href="#Gradient-Algorithm-with-Exact-Line-Search" class="headerlink" title="Gradient Algorithm with Exact Line-Search"></a>Gradient Algorithm with Exact Line-Search</h3><h2 id="The-Pure-Newton-Method"><a href="#The-Pure-Newton-Method" class="headerlink" title="The Pure Newton Method"></a>The Pure Newton Method</h2>
            </div>
        </article>
    </div>


      <div class="post-toc-warp">
        
      <!--noindex-->
          <div class="post-toc" id="toc-test">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#1-梯度法"><span class="nav-text">1. 梯度法</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Gradient-Algorithm-with-Exact-Line-Search"><span class="nav-text">Gradient Algorithm with Exact Line-Search</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#The-Pure-Newton-Method"><span class="nav-text">The Pure Newton Method</span></a></li></ol></div>
            

            <div class="back-to-top" id="back-to-top">
              <i class="iconfont icon-up"></i>
            </div>

          </div>
      <!--/noindex-->
      
      </div>


      </div>
      <footer id="colophon"><span class="copyright-year">
    
        &copy;
    
        2017 -
    
    2019
    <span class="footer-author">haoyu.</span>
    <span class="power-by">
        Powered by <a class="hexo-link" href="https://hexo.io/">Hexo</a> and <a class="theme-link" href="https://github.com/henryhuang/hexo-theme-polarbearsimple">Polar Bear Simple</a>
    </span>
</span>

      </footer>


    </div>
    


    




  
    <script type="text/javascript" src="/lib/jquery/jquery-3.1.1.min.js"></script>
  

  

    <script type="text/javascript" src="/js/src/theme.js?v=1.1"></script>
<script type="text/javascript" src="/js/src/bootstrap.js?v=1.1"></script>

  </body>
</html>
