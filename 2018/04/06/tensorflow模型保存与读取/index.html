<!DOCTYPE html>
<html lang>
  <head><meta name="generator" content="Hexo 3.9.0">
    
<meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0, minimum-scale=0.5, maximum-scale=2.0, user-scalable=yes">


<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">



  <meta name="description" content="TesnsorFlow 模型的保存于读取">




  <meta name="keywords" content="python,深度学习,">







  <link rel="alternate" href="/atom.xml" title="浩瀚宇宙·AaronChen">




  <link rel="shortcut icon" type="image/x-icon" href="/img/1.jpg?v=1.1">



<link rel="canonical" href="https://hhyz.me/2018/04/06/tensorflow模型保存与读取/">


<meta name="description" content="模型的保存于读取保存12345678910111213141516import tensorflow as tf# 声明两个变量v1 = tf.Variable(tf.random_normal([1, 2]), name=&quot;v1&quot;)v2 = tf.Variable(tf.random_normal([2, 3]), name=&quot;v2&quot;)init_op = tf.global_variables_">
<meta name="keywords" content="python,深度学习">
<meta property="og:type" content="article">
<meta property="og:title" content="TesnsorFlow 模型的保存于读取">
<meta property="og:url" content="https://hhyz.me/2018/04/06/tensorflow模型保存与读取/index.html">
<meta property="og:site_name" content="浩瀚宇宙·AaronChen">
<meta property="og:description" content="模型的保存于读取保存12345678910111213141516import tensorflow as tf# 声明两个变量v1 = tf.Variable(tf.random_normal([1, 2]), name=&quot;v1&quot;)v2 = tf.Variable(tf.random_normal([2, 3]), name=&quot;v2&quot;)init_op = tf.global_variables_">
<meta property="og:locale" content="zh">
<meta property="og:updated_time" content="2019-07-02T17:05:20.594Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="TesnsorFlow 模型的保存于读取">
<meta name="twitter:description" content="模型的保存于读取保存12345678910111213141516import tensorflow as tf# 声明两个变量v1 = tf.Variable(tf.random_normal([1, 2]), name=&quot;v1&quot;)v2 = tf.Variable(tf.random_normal([2, 3]), name=&quot;v2&quot;)init_op = tf.global_variables_">


<link rel="stylesheet" type="text/css" href="/css/style.css?v=1.1">
<link href="https://fonts.googleapis.com/css?family=Open+Sans" rel="stylesheet">





<script type="text/javascript">
  var themeConfig = {
    fancybox: {
      enable: false
    },
  };
</script>




  
  <script type="text/javascript">
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?3cbfa43ed54bb06d8da192dc667bed80";
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(hm, s);
    })();
  </script>


  <script type="text/javascript">
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
        (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
        m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
        })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

        ga('create', 'UA-139198240-1', 'auto');
        ga('send', 'pageview');
  </script>





  
    <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
    <script>
      (adsbygoogle = window.adsbygoogle || []).push({
        google_ad_client: "ca-pub-9937341197542093",
        enable_page_level_ads: true
      });
    </script>



    <title> TesnsorFlow 模型的保存于读取 - 浩瀚宇宙·AaronChen </title>


    <script>
(function(u, c) {
  var d = document, t = 'script', o = d.createElement(t),
      s = d.getElementsByTagName(t)[0];
  o.src = u;
  if (c) { o.addEventListener('load', function(e) { c(e); }); }
  s.parentNode.insertBefore(o, s);
})('//cdn.bootcss.com/pangu/3.3.0/pangu.min.js', function() {
  pangu.spacingPage();
});
</script>



<script type="text/javascript">
window.onload=
function(){
    var oDiv = document.getElementById("toc-test"),
    H = 0,
    Y = oDiv
    while (Y) {H += Y.offsetTop; Y = Y.offsetParent}
    window.onscroll = function()
    {
        var s = document.body.scrollTop || document.documentElement.scrollTop
        if(s>H) {
            oDiv.style = "position:fixed;top:0;"
        } else {
            oDiv.style = ""
        }
    }
}
</script>






  </head>

  <body>
    <div id="page">
      <header id="masthead"><div class="site-header-inner">
    <h1 class="site-title">
        <a href="/." class="logo">浩瀚宇宙·AaronChen</a>
    </h1>

    <nav id="nav-top">
        
            <ul id="menu-top" class="nav-top-items">
                
                    <li class="menu-item">
                        <a href="https://www.hhyz.me">
                            
                            
                                Gallery
                            
                        </a>
                    </li>
                
                    <li class="menu-item">
                        <a href="/about">
                            
                            
                                About
                            
                        </a>
                    </li>
                
            </ul>
        
  </nav>
</div>

      </header>
      <div id="content">
        
    <div id="primary">
        
  <article class="post">
    <header class="post-header">
      <h1 class="post-title">
        
          TesnsorFlow 模型的保存于读取
        
      </h1>

      <time class="post-time">
          Apr 6 2018
      </time>
    </header>



    
            <div class="post-content">
            <h2 id="模型的保存于读取"><a href="#模型的保存于读取" class="headerlink" title="模型的保存于读取"></a>模型的保存于读取</h2><h3 id="保存"><a href="#保存" class="headerlink" title="保存"></a>保存</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line"><span class="comment"># 声明两个变量</span></span><br><span class="line">v1 = tf.Variable(tf.random_normal([<span class="number">1</span>, <span class="number">2</span>]), name=<span class="string">"v1"</span>)</span><br><span class="line">v2 = tf.Variable(tf.random_normal([<span class="number">2</span>, <span class="number">3</span>]), name=<span class="string">"v2"</span>)</span><br><span class="line">init_op = tf.global_variables_initializer() <span class="comment"># 初始化全部变量</span></span><br><span class="line"></span><br><span class="line">saver = tf.train.Saver() <span class="comment"># 声明tf.train.Saver类用于保存模型</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    sess.run(init_op)</span><br><span class="line">    print(<span class="string">"v1:"</span>, sess.run(v1)) <span class="comment"># 打印v1、v2的值一会读取之后对比</span></span><br><span class="line">    print(<span class="string">"v2:"</span>, sess.run(v2))</span><br><span class="line">    </span><br><span class="line">    saver_path = saver.save(sess, <span class="string">"save/model.ckpt"</span>)  <span class="comment"># 将模型保存到save/model.ckpt文件</span></span><br><span class="line">    print(<span class="string">"Model saved in file:"</span>, saver_path)</span><br></pre></td></tr></table></figure>

<figure class="highlight lua"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">v1: <span class="string">[[-0.33648431 -0.46078524]]</span></span><br><span class="line">v2: <span class="string">[[-0.73017526 -0.42726403  1.74622989]</span></span><br><span class="line"><span class="string"> [-1.50939059 -0.87901741  0.94227242]]</span></span><br><span class="line">Model saved <span class="keyword">in</span> file: save/model.ckpt</span><br></pre></td></tr></table></figure>

<p>这段代码中，通过saver.save函数将TensorFlow模型保存到了save/model.ckpt文件中，这里代码中指定路径为”save/model.ckpt”，也就是保存到了当前程序所在文件夹里面的save文件夹中。</p>
<a id="more"></a>

<p>TensorFlow模型会保存在后缀为.ckpt的文件中。保存后在save这个文件夹中实际会出现3个文件，因为TensorFlow会将计算图的结构和图上参数取值分开保存。</p>
<ul>
<li>model.ckpt.meta文件保存了TensorFlow计算图的结构，可以理解为神经网络的网络结构</li>
<li>model.ckpt文件保存了TensorFlow程序中每一个变量的取值</li>
<li>checkpoint文件保存了一个目录下所有的模型文件列表</li>
</ul>
<h3 id="读取"><a href="#读取" class="headerlink" title="读取"></a>读取</h3><p><strong>方法1</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用和保存模型代码中一样的方式来声明变量</span></span><br><span class="line">v1 = tf.Variable(tf.random_normal([<span class="number">1</span>, <span class="number">2</span>]), name=<span class="string">"v1"</span>)</span><br><span class="line">v2 = tf.Variable(tf.random_normal([<span class="number">2</span>, <span class="number">3</span>]), name=<span class="string">"v2"</span>)</span><br><span class="line">saver = tf.train.Saver() <span class="comment"># 声明tf.train.Saver类用于保存模型</span></span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    saver.restore(sess, <span class="string">"save/model.ckpt"</span>) <span class="comment"># 即将固化到硬盘中的Session从保存路径再读取出来</span></span><br><span class="line">    print(<span class="string">"v1:"</span>, sess.run(v1)) <span class="comment"># 打印v1、v2的值和之前的进行对比</span></span><br><span class="line">    print(<span class="string">"v2:"</span>, sess.run(v2))</span><br><span class="line">    print(<span class="string">"Model Restored"</span>)</span><br></pre></td></tr></table></figure>

<figure class="highlight lua"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">v1: <span class="string">[[ 0.22189325  0.81017244]]</span></span><br><span class="line">v2: <span class="string">[[-0.99802715 -0.54230249  1.92878962]</span></span><br><span class="line"><span class="string"> [ 1.04581845  0.25543991 -0.6358065 ]]</span></span><br><span class="line">Model Restored</span><br></pre></td></tr></table></figure>

<p>这段加载模型的代码基本上和保存模型的代码是一样的。也是先定义了TensorFlow计算图上所有的运算，并声明了一个tf.train.Saver类。两段唯一的不同是，在加载模型的代码中没有运行变量的初始化过程，而是将变量的值通过已经保存的模型加载进来。 </p>
<p><strong>方法2</strong></p>
<p>如果不希望重复定义图上的运算，也可以直接加载已经持久化的图：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="comment"># 在下面的代码中，默认加载了TensorFlow计算图上定义的全部变量</span></span><br><span class="line"><span class="comment"># 直接加载持久化的图</span></span><br><span class="line">saver = tf.train.import_meta_graph(<span class="string">"save/model.ckpt.meta"</span>)</span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    saver.restore(sess, <span class="string">"save/model.ckpt"</span>)</span><br><span class="line">    <span class="comment"># 通过张量的名称来获取张量</span></span><br><span class="line">    print(sess.run(tf.get_default_graph().get_tensor_by_name(<span class="string">"v1:0"</span>)))</span><br></pre></td></tr></table></figure>

<figure class="highlight lua"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">[[ 0.22189325  0.81017244]]</span></span><br></pre></td></tr></table></figure>

<p><strong>恢复操作和其它元数据</strong></p>
<p>我想分享的最后一个信息是，<strong>Saver</strong>将保存与图有关联的任何元数据。这就意味着，当我们恢复一个模型的时候，我们还同时恢复了所有与图相关的变量、操作和集合。</p>
<p>当我们恢复一个元模型（restore a meta checkpoint）时，实际上我们执行的操作是将恢复的图载入到当前的默认图中。所有当你完成模型恢复之后，你可以在默认图中访问载入的任何内容，比如一个张量，一个操作或者集合。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf </span><br><span class="line"></span><br><span class="line"><span class="comment"># Let's laod a previous meta graph in the current graph in use: usually the default graph </span></span><br><span class="line"><span class="comment"># This actions returns a Saver </span></span><br><span class="line">saver = tf.train.import_meta_graph(<span class="string">'results/model.ckpt-1000.meta'</span>) </span><br><span class="line"></span><br><span class="line"><span class="comment"># We can now access the default graph where all our metadata has been loaded </span></span><br><span class="line">graph = tf.get_default_graph() </span><br><span class="line"></span><br><span class="line"><span class="comment"># Finally we can retrieve tensors, operations, etc. </span></span><br><span class="line">global_step_tensor = graph.get_tensor_by_name(<span class="string">'loss/global_step:0'</span>)</span><br><span class="line">train_op = graph.get_operation_by_name(<span class="string">'loss/train_op'</span>) </span><br><span class="line">hyperparameters = tf.get_collection(<span class="string">'hyperparameters'</span>)</span><br></pre></td></tr></table></figure>



<p><strong>在新图中导入预训练模型</strong></p>
<p>至此，你应该已经明白了如何去保存和恢复一个模型。然而，我们还可以使用一些技巧去帮助你更快的保存和恢复一个模型。比如：</p>
<ul>
<li>一个图的输出能成为另一个图的输入吗？</li>
</ul>
<p>答案是确定的。但是目前我的做法是先将第一个图进行保存，然后在另一个图中进行恢复。但是这种方案感觉很笨重，我不知道是否有更好的方法。</p>
<p>但是这种方法确实能工作，除非你想要去重新训练第一个图。在这种情况下，你需要将输入的梯度重新输入到第一张图中的特定的训练步骤中。我想你已经被这种复杂的方案给逼疯了把。:-)</p>
<ul>
<li>我可以在一个图中混合不同的图吗？</li>
</ul>
<p>答案当然是肯定的，但是你必须非常小心命名空间。这种方法有一点好处是，简化了一切。比如，你可以预加载一个VGG-19模型。然后访问图中的任何节点，并执行你自己的后续操作，从而训练一整个完整的模型。</p>
<p>如果你只想微调你自己的节点，那么你可以在你想要的地方中断梯度。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line"><span class="comment"># Load the VGG-16 model in the default graph</span></span><br><span class="line">vgg_saver = tf.train.import_meta_graph(dir + <span class="string">'/vgg/results/vgg-16.meta'</span>)</span><br><span class="line"><span class="comment"># Access the graph</span></span><br><span class="line">vgg_graph = tf.get_default_graph()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Retrieve VGG inputs</span></span><br><span class="line">self.x_plh = vgg_graph.get_tensor_by_name(<span class="string">'input:0'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Choose which node you want to connect your own graph</span></span><br><span class="line">output_conv =vgg_graph.get_tensor_by_name(<span class="string">'conv1_2:0'</span>)</span><br><span class="line"><span class="comment"># output_conv =vgg_graph.get_tensor_by_name('conv2_2:0')</span></span><br><span class="line"><span class="comment"># output_conv =vgg_graph.get_tensor_by_name('conv3_3:0')</span></span><br><span class="line"><span class="comment"># output_conv =vgg_graph.get_tensor_by_name('conv4_3:0')</span></span><br><span class="line"><span class="comment"># output_conv =vgg_graph.get_tensor_by_name('conv5_3:0')</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Stop the gradient for fine-tuning</span></span><br><span class="line">output_conv_sg = tf.stop_gradient(output_conv) <span class="comment"># It's an identity function</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Build further operations</span></span><br><span class="line">output_conv_shape = output_conv_sg.get_shape().as_list()</span><br><span class="line">W1 = tf.get_variable(<span class="string">'W1'</span>, shape=[<span class="number">1</span>, <span class="number">1</span>, output_conv_shape[<span class="number">3</span>], <span class="number">32</span>], initializer=tf.random_normal_initializer(stddev=<span class="number">1e-1</span>))</span><br><span class="line">b1 = tf.get_variable(<span class="string">'b1'</span>, shape=[<span class="number">32</span>], initializer=tf.constant_initializer(<span class="number">0.1</span>))</span><br><span class="line">z1 = tf.nn.conv2d(output_conv_sg, W1, strides=[<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>], padding=<span class="string">'SAME'</span>) + b1</span><br><span class="line">a = tf.nn.relu(z1)</span><br></pre></td></tr></table></figure>




<h2 id="数据增强"><a href="#数据增强" class="headerlink" title="数据增强"></a>数据增强</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 随机裁剪图片</span></span><br><span class="line"><span class="comment"># Randomly crop a [height, width] section of the image.</span></span><br><span class="line">distorted_image = tf.random_crop(reshaped_image, [height, width, <span class="number">3</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 随机翻转图片，每张图片有50%的概率被水平左右翻转，另有50%的概率保持不变</span></span><br><span class="line"><span class="comment"># Randomly flip the image horizontally.</span></span><br><span class="line">distorted_image = tf.image.random_flip_left_right(distorted_image)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 随机改变亮度和对比度</span></span><br><span class="line"><span class="comment"># Because these operations are not commutative, consider randomizing</span></span><br><span class="line"><span class="comment"># the order their operation.</span></span><br><span class="line">distorted_image = tf.image.random_brightness(distorted_image,</span><br><span class="line">                                             max_delta=<span class="number">63</span>)</span><br><span class="line">distorted_image = tf.image.random_contrast(distorted_image,</span><br><span class="line">                                           lower=<span class="number">0.2</span>, upper=<span class="number">1.8</span>)</span><br></pre></td></tr></table></figure>

<p>原始的训练图片是 <code>reshaped_image</code>，最后会得到一个数据增强后的训练样本 <code>distorted_image</code>。 训练时，直接使用 <code>distorted_image</code> 进行训练即可</p>
<figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">转载与参考：</span><br><span class="line">http:<span class="regexp">//</span>www.cnblogs.com<span class="regexp">/seaspring/</span>  </span><br><span class="line">https:<span class="regexp">//</span>www.jianshu.com<span class="regexp">/p/</span><span class="number">8487</span>db911d9a</span><br></pre></td></tr></table></figure>
            </div>
          

    
      <footer class="post-footer">
        <div class="post-tags">
          
            <a href="/tags/python/">python</a>
          
            <a href="/tags/深度学习/">深度学习</a>
          
        </div>

        <div class="post-tags">
          
            <a href="/categories/TensorFlow/">TensorFlow</a>
          
        </div>

        
        
  <nav class="post-nav">
    
      <a class="prev" href="/2018/04/11/SPPNet/">
        <i class="iconfont icon-left"></i>
        <span class="prev-text nav-default">SPP-Net 目标检测（二）</span>
        <span class="prev-text nav-mobile">Prev</span>
      </a>
    
    
      <a class="next" href="/2018/04/05/base64/">
        <span class="next-text nav-default">计算机编码：base64</span>
        <span class="prev-text nav-mobile">Next</span>
        <i class="iconfont icon-right"></i>
      </a>
    
  </nav>

        
  <div class="comments" id="comments">
    
  </div>


      </footer>
    
  </article>

    </div>


      <div class="post-toc-warp">
        
      <!--noindex-->
          <div class="post-toc" id="toc-test">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#模型的保存于读取"><span class="nav-text">模型的保存于读取</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#保存"><span class="nav-text">保存</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#读取"><span class="nav-text">读取</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#数据增强"><span class="nav-text">数据增强</span></a></li></ol></div>
            

            <div class="back-to-top" id="back-to-top">
              <i class="iconfont icon-up"></i>
            </div>

          </div>
      <!--/noindex-->
      
      </div>


      </div>
      <footer id="colophon"><span class="copyright-year">
    
        &copy;
    
        2017 -
    
    2019
    <span class="footer-author">haoyu.</span>
    <span class="power-by">
        Powered by <a class="hexo-link" href="https://hexo.io/">Hexo</a> and <a class="theme-link" href="https://github.com/henryhuang/hexo-theme-polarbearsimple">Polar Bear Simple</a>
    </span>
</span>

      </footer>


    </div>
    


    




  
    <script type="text/javascript" src="/lib/jquery/jquery-3.1.1.min.js"></script>
  

  

    <script type="text/javascript" src="/js/src/theme.js?v=1.1"></script>
<script type="text/javascript" src="/js/src/bootstrap.js?v=1.1"></script>

  </body>
</html>
